developing these algorithms is very difficult due to their extreme nature, having to work with both the very small and very large cases in the same graph dynamically as the algorithm progresses for maximum performance. It also makes dealing with edge cases a must because they WILL come for you...

debugging:

1. rank 0: level 2: 0 9 4 6 (remote counts) after process_frontier
  - same as level 1...

2. must be processing same frontier
  - frontier of lvl2 is next frontier of lvl 1

3. process frontier adds local neighbors to next frontier


~~~~

  - for each vertex in current frontier add each local neighbor to next_frontier

    - non-local neighbors to remote_vertices to be sent (still neigbors of current frontier so belonging in next frontier)

  - lots of organization and sizes to pass remote vertices to each other

  - go through your list of recv vertices and add them to next frontier (each node looked in it's graph) 

  - now each node holds its current frontier and all neighbors of frontier in next_frontier

~~~~

  - chcek to see if nothing was passed and swap frontiers, loop


===

is the problem really in swap_kernel???? -- yes it was
